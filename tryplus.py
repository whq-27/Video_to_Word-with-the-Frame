import os
import sys
import shutil
import cv2
import re
import whisper
import yt_dlp
from datetime import datetime
from docx import Document
from docx.shared import Inches, Pt, RGBColor
from docx.oxml.ns import qn
from docx.enum.text import WD_ALIGN_PARAGRAPH
import warnings

# --- å¿…é¡»ä¾èµ– ---
try:
    from openai import OpenAI
except ImportError:
    print("âŒ ç¼ºå°‘ openai åº“ï¼Œè¯·è¿è¡Œ: pip install openai")
    sys.exit(1)

warnings.filterwarnings("ignore")

# ================= é…ç½®åŒºåŸŸ =================
# 1. Bç«™ Cookie
COOKIE_PATH = '/big-data/person/wanghaoqi/try/www.bilibili.com_cookies.txt'

# 2. é»˜è®¤å­˜å‚¨æ ¹ç›®å½•
DEFAULT_OUTPUT_BASE = "/big-data/person/wanghaoqi/try/output"

# 3. LLM é…ç½®
LLM_API_KEY = "sk-*************************************" 
LLM_BASE_URL = "https://api.deepseek.com"          
LLM_MODEL = "deepseek-chat"                       

# 4. å±å¹•é€‚é…å‚æ•°
MAX_SUBTITLE_LENGTH = 20  # æ¯è¡Œå­—å¹•æœ€å¤§å­—æ•°
# ===========================================

class VideoToWordConverter:
    def __init__(self, model_size="base"):
        self.check_ffmpeg()
        self.model_size = model_size
        self.model = None
        self.video_path = None      
        self.img_output_dir = None
        self.video_title_stem = "video_report"
        
        self.llm_client = None
        if LLM_API_KEY:
            try:
                self.llm_client = OpenAI(api_key=LLM_API_KEY, base_url=LLM_BASE_URL)
                print(f"[ç³»ç»Ÿ] LLM å®¢æˆ·ç«¯å·²å°±ç»ª: {LLM_MODEL}")
            except Exception as e:
                print(f"âš ï¸ LLM åˆå§‹åŒ–å¤±è´¥: {e}")

    def check_ffmpeg(self):
        if not shutil.which("ffmpeg"):
            print("âŒ é”™è¯¯: æœªæ£€æµ‹åˆ° FFmpegã€‚")
            sys.exit(1)

    def _load_model(self):
        if self.model is None:
            print(f"[ç³»ç»Ÿ] æ­£åœ¨åŠ è½½ Whisper æ¨¡å‹ ({self.model_size})...")
            try:
                self.model = whisper.load_model(self.model_size)
            except Exception as e:
                print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
                sys.exit(1)

    def sanitize_filename(self, title):
        return re.sub(r'[\\/*?:"<>|]', "", title).strip()

    def prepare_source(self, user_input, output_dir):
        user_input = user_input.strip('"').strip("'")
        if os.path.exists(user_input):
            abs_path = os.path.abspath(user_input)
            print(f"âœ… æ£€æµ‹åˆ°æœ¬åœ°æ–‡ä»¶: {abs_path}")
            self.video_path = abs_path
            filename = os.path.basename(abs_path)
            self.video_title_stem = os.path.splitext(filename)[0]
            return True
        elif user_input.startswith(('http://', 'https://', 'www.')):
            print(f"ğŸŒ æ£€æµ‹åˆ°ç½‘ç»œé“¾æ¥ï¼Œå‡†å¤‡è·å–æ ‡é¢˜å¹¶ä¸‹è½½...")
            return self.download_video(user_input, output_dir)
        else:
            print("âŒ è¾“å…¥æ— æ•ˆã€‚")
            return False

    def download_progress_hook(self, d):
        if d['status'] == 'finished':
            print(f"    -> âœ… æµä¸‹è½½å®Œæˆ ({d.get('_total_bytes_str', 'æœªçŸ¥')})...")

    def download_video(self, url, output_dir):
        use_cookie = os.path.exists(COOKIE_PATH)
        info_opts = {'quiet': True, 'no_warnings': True, 'user_agent': 'Mozilla/5.0...'}
        if use_cookie: info_opts['cookiefile'] = COOKIE_PATH

        print(f"[1/5] è·å–è§†é¢‘æ ‡é¢˜...")
        try:
            with yt_dlp.YoutubeDL(info_opts) as ydl:
                info = ydl.extract_info(url, download=False)
                title = info.get('title', 'downloaded_video')
            self.video_title_stem = self.sanitize_filename(title)
            print(f"   -> æ ‡é¢˜: {title}")
        except:
            self.video_title_stem = f"video_{datetime.now().strftime('%H%M%S')}"

        ydl_opts = {
            'format': 'bestvideo[vcodec^=avc]+bestaudio/best', 
            'merge_output_format': 'mp4',
            'outtmpl': os.path.join(output_dir, f"{self.video_title_stem}.%(ext)s"),
            'quiet': True, 'no_warnings': True,
            'progress_hooks': [self.download_progress_hook],
            'user_agent': 'Mozilla/5.0...'
        }
        if use_cookie: ydl_opts['cookiefile'] = COOKIE_PATH
        
        try:
            print(f"[2/5] æ­£åœ¨ä¸‹è½½ç´ æ (H.264)...")
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                ydl.download([url])
            
            self.video_path = None
            for f in os.listdir(output_dir):
                if f == "images": continue
                if f.lower().endswith(('.mp4', '.mkv', '.webm')):
                    self.video_path = os.path.abspath(os.path.join(output_dir, f))
                    break
            if not self.video_path:
                self.video_path = os.path.abspath(os.path.join(output_dir, f"{self.video_title_stem}.mp4"))
            print(f"âœ… ä¸‹è½½å®Œæˆ: {self.video_path}")
            return True
        except Exception as e:
            print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
            return False

    # ================= æ ¸å¿ƒå¤„ç†é€»è¾‘ =================

    def generate_summary(self, sentences_list):
        if not self.llm_client or not sentences_list: return None
        full_text = "".join([s['text'] for s in sentences_list])
        print(f"   -> æ­£åœ¨ç”Ÿæˆ AI æ€»ç»“ (å…¨æ–‡å…± {len(full_text)} å­—)...")
        prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¼šè®®çºªè¦åŠ©æ‰‹ã€‚è¯·æ ¹æ®è§†é¢‘å­—å¹•ç”Ÿæˆä¸€ä»½ç»“æ„åŒ–æ€»ç»“ã€‚
            è¦æ±‚ï¼š
            1. **ä¸€å¥è¯æ‘˜è¦**ï¼šç²¾ç‚¼æ¦‚æ‹¬ã€‚
            2. **æ ¸å¿ƒè§‚ç‚¹**ï¼šåˆ—å‡º3-5ä¸ªå…³é”®ç‚¹ã€‚
            3. **è¯¦ç»†è„‰ç»œ**ï¼šæŒ‰é€»è¾‘æ¢³ç†å†…å®¹ã€‚
            è¯·ä½¿ç”¨ Markdown æ ¼å¼ (###, **, - )ã€‚"""
        try:
            safe_text = full_text[:30000] 
            response = self.llm_client.chat.completions.create(
                model=LLM_MODEL,
                messages=[
                    {"role": "system", "content": prompt},
                    {"role": "user", "content": f"å­—å¹•å†…å®¹ï¼š\n{safe_text}"}
                ],
                stream=False
            )
            return response.choices[0].message.content
        except Exception as e:
            print(f"âš ï¸ æ€»ç»“ç”Ÿæˆå¤±è´¥: {e}")
            return None

    def clean_text_minimal(self, text):
        if not self.llm_client or len(text) < 4: return text
        prompt = f"""ä»»åŠ¡ï¼šæç®€æ¸…æ´—å­—å¹•ã€‚
            åŸåˆ™ï¼š
            1. ä»…åˆ é™¤å£è¯¯ã€é‡å¤è¯ã€è¯­æ°”åŠ©è¯ï¼ˆå‘ƒã€é‚£ä¸ªï¼‰ã€‚
            2. ã€ä¸¥ç¦ã€‘æ”¹å†™å¥å­ç»“æ„ã€‚
            3. ã€ä¸¥ç¦ã€‘åˆ å‡å®ä¹‰å†…å®¹ã€‚
            åŸæ–‡ï¼š{text}"""
        try:
            response = self.llm_client.chat.completions.create(
                model=LLM_MODEL,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.1, 
                stream=False
            )
            cleaned = response.choices[0].message.content.strip()
            if not cleaned: return text
            return cleaned
        except:
            return text

    def smart_split_subtitle(self, start, end, text, max_chars):
        total_duration = end - start
        pattern = r'([ï¼Œã€‚ï¼Ÿï¼ï¼›ï¼šã€,?!;:\s])'
        parts = re.split(pattern, text)
        parts = [p for p in parts if p]
        
        chunks = []
        current_chunk = ""
        
        for part in parts:
            if len(part) == 1 and re.match(pattern, part):
                current_chunk += part
                continue
            if len(current_chunk) + len(part) <= max_chars:
                current_chunk += part
            else:
                if current_chunk: chunks.append(current_chunk)
                current_chunk = ""
                if len(part) > max_chars:
                    for k in range(0, len(part), max_chars):
                        chunks.append(part[k:k+max_chars])
                else:
                    current_chunk = part
        if current_chunk: chunks.append(current_chunk)
        
        final_segments = []
        current_start = start
        clean_total_len = sum(len(c) for c in chunks)
        
        for chunk in chunks:
            ratio = len(chunk) / clean_total_len if clean_total_len > 0 else 0
            chunk_duration = total_duration * ratio
            chunk_end = current_start + chunk_duration
            final_segments.append({
                "start": current_start,
                "end": chunk_end,
                "text": chunk.strip()
            })
            current_start = chunk_end
        return final_segments

    def process_dual_version(self, raw_segments):
        print(f"   -> æ­£åœ¨è¿›è¡Œè¯­ä¹‰åˆå¹¶ (ä¿®å¤ä¸åˆç†æ¢è¡Œ)...")
        merged_sentences = []
        buffer_text = ""
        buffer_start = 0.0
        strong_endings = re.compile(r'[ã€‚ï¼ï¼Ÿ\.\!\?]')
        weak_endings = re.compile(r'[ï¼Œ,ã€]')
        
        for i, seg in enumerate(raw_segments):
            text = seg['text']
            if buffer_text == "": buffer_start = seg['start']
            buffer_text += text
            is_strong = strong_endings.search(text)
            is_long_weak = len(buffer_text) > 150 and weak_endings.search(text)
            is_too_long = len(buffer_text) > 500
            is_end = is_strong or is_long_weak or is_too_long or (i == len(raw_segments)-1)
            
            if is_end:
                full_sent = buffer_text.strip().replace('\n', '').replace('\r', '')
                if full_sent:
                    merged_sentences.append({
                        "start": buffer_start,
                        "end": seg['end'],
                        "text": full_sent
                    })
                buffer_text = ""
        
        print(f"   -> åˆå¹¶å®Œæˆã€‚å…± {len(merged_sentences)} ä¸ªå®Œæ•´å¥ã€‚")
        ai_summary = self.generate_summary(merged_sentences)
        if ai_summary: print("âœ… AI æ€»ç»“ç”Ÿæˆå®Œæ¯•ã€‚")

        final_raw_list = []
        final_ai_list = []
        total = len(merged_sentences)
        
        print("   -> å¼€å§‹é€å¥å¤„ç† (åŒè½¨ç”Ÿæˆ)...")
        for i, item in enumerate(merged_sentences):
            sys.stdout.write(f"\r      è¿›åº¦: {i+1}/{total}...")
            sys.stdout.flush()
            raw_subs = self.smart_split_subtitle(
                item['start'], item['end'], item['text'], MAX_SUBTITLE_LENGTH
            )
            final_raw_list.extend(raw_subs)
            if self.llm_client:
                cleaned_text = self.clean_text_minimal(item['text'])
            else:
                cleaned_text = item['text']
            ai_subs = self.smart_split_subtitle(
                item['start'], item['end'], cleaned_text, MAX_SUBTITLE_LENGTH
            )
            final_ai_list.extend(ai_subs)
            
        print(f"\n   -> å­—å¹•å¤„ç†å®Œæˆã€‚")
        return ai_summary, merged_sentences, final_raw_list, final_ai_list

    # ==================================================

    def run(self, user_input, output_task_dir):
        if not self.prepare_source(user_input, output_task_dir): return
        self._load_model()

        print("[3/5] æ­£åœ¨è¿›è¡Œè¯­éŸ³è¯†åˆ«...")
        try:
            result = self.model.transcribe(
                self.video_path, fp16=False, language='zh',
                initial_prompt="ä»¥ä¸‹æ˜¯ç®€ä½“ä¸­æ–‡å­—å¹•ï¼ŒåŒ…å«å®Œæ•´çš„æ ‡ç‚¹ç¬¦å·ã€‚"
            )
            ai_summary, merged_sentences, raw_list, ai_list = self.process_dual_version(result["segments"])
        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥: {e}")
            return

        final_docx_name = f"{self.video_title_stem}.docx"
        final_docx_path = os.path.join(output_task_dir, final_docx_name)
        self.generate_dual_docx(ai_summary, merged_sentences, raw_list, ai_list, final_docx_path)

    # --- ã€å…³é”®ã€‘æ–°å¢åŠ çš„å­—ä½“å¼ºåˆ¶å‡½æ•° ---
    def add_heading_force_font(self, doc, text, level):
        """æ·»åŠ æ ‡é¢˜å¹¶å¼ºåˆ¶åº”ç”¨ä¸­æ–‡å­—ä½“"""
        heading = doc.add_heading(text, level)
        for run in heading.runs:
            run.font.name = u'å¾®è½¯é›…é»‘'
            run._element.rPr.rFonts.set(qn('w:eastAsia'), u'å¾®è½¯é›…é»‘')
            # å¯é€‰ï¼šå¦‚æœä½ å¸Œæœ›æ ‡é¢˜æ˜¯é»‘è‰²çš„ï¼Œè€Œä¸æ˜¯Wordé»˜è®¤çš„è“è‰²ï¼Œå¯ä»¥å–æ¶ˆä¸‹é¢æ³¨é‡Š
            # run.font.color.rgb = RGBColor(0, 0, 0)
        return heading

    def generate_dual_docx(self, summary, merged_sentences, raw_list, ai_list, output_docx):
        print(f"[4/5] æ­£åœ¨ç”Ÿæˆ Word æ–‡æ¡£...")
        abs_output_path = os.path.abspath(output_docx)
        current_task_dir = os.path.dirname(abs_output_path) 
        self.img_output_dir = os.path.join(current_task_dir, "images")
        if not os.path.exists(self.img_output_dir): os.makedirs(self.img_output_dir)

        doc = Document()
        
        # åŸºç¡€æ ·å¼è®¾ç½® (å…œåº•)
        doc.styles['Normal'].font.name = u'å¾®è½¯é›…é»‘'
        doc.styles['Normal']._element.rPr.rFonts.set(qn('w:eastAsia'), u'å¾®è½¯é›…é»‘')

        # ä½¿ç”¨å¼ºåˆ¶å­—ä½“å‡½æ•°æ·»åŠ æ ‡é¢˜
        self.add_heading_force_font(doc, self.video_title_stem, 0)
        
        doc.add_paragraph(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        doc.add_paragraph(f"è§†é¢‘è·¯å¾„: {self.video_path}") 
        
        if summary:
            self.add_heading_force_font(doc, 'ğŸ’¡ AI æ™ºèƒ½æ€»ç»“', 1)
            self.render_markdown_to_word(doc, summary)
            doc.add_page_break()

        self.add_heading_force_font(doc, 'ç¬¬ä¸€éƒ¨åˆ†ï¼šå­—å¹•å…¨æ–‡å¯¹æ¯”', 1)
        
        self.add_heading_force_font(doc, '1.1 åŸå§‹å…¨æ–‡ (æœªä¼˜åŒ–)', 2)
        self.add_smart_paragraphs(doc, merged_sentences, use_ai_clean=False)
        
        self.add_heading_force_font(doc, '1.2 AIä¼˜åŒ–å…¨æ–‡ (å»å£ç™–/å¾®è°ƒ)', 2)
        self.add_smart_paragraphs(doc, merged_sentences, use_ai_clean=True)
        
        doc.add_page_break()

        self.add_heading_force_font(doc, 'ç¬¬äºŒéƒ¨åˆ†ï¼šå›¾æ–‡å¯¹ç…§ (AIä¼˜åŒ–ç‰ˆ)', 1)
        doc.add_paragraph("æ³¨ï¼šæ­¤ç‰ˆæœ¬å»é™¤äº†å£è¯­åºŸè¯ï¼Œé˜…è¯»æ›´æµç•…ã€‚")
        self.create_image_table(doc, ai_list)
        
        doc.add_page_break()
        
        self.add_heading_force_font(doc, 'ç¬¬ä¸‰éƒ¨åˆ†ï¼šå›¾æ–‡å¯¹ç…§ (åŸå§‹é€å­—ç‰ˆ)', 1)
        doc.add_paragraph("æ³¨ï¼šæ­¤ç‰ˆæœ¬å®Œå…¨å¿ å®äºåŸéŸ³é¢‘ã€‚")
        self.create_image_table(doc, raw_list)

        try:
            doc.save(abs_output_path)
            print(f"\nâœ… å®Œæˆï¼\n   ğŸ“„ æ–‡æ¡£: {abs_output_path}\n   ğŸ–¼ï¸ å›¾ç‰‡: {self.img_output_dir}\n   ğŸ¥è§†é¢‘ï¼š{self.video_path}")
        except PermissionError: print(f"âŒ ä¿å­˜å¤±è´¥: è¯·å…³é—­æ–‡æ¡£åé‡è¯•ï¼")
        except Exception as e: print(f"âŒ ä¿å­˜å‡ºé”™: {e}")

    def render_markdown_to_word(self, doc, text):
        for line in text.split('\n'):
            line = line.strip()
            if not line: continue
            if line.startswith('### '):
                self.add_heading_force_font(doc, line.replace('### ', ''), 3)
            elif line.startswith('## '):
                self.add_heading_force_font(doc, line.replace('## ', ''), 2)
            elif line.startswith('**') and line.endswith('**'):
                p = doc.add_paragraph()
                run = p.add_run(line.replace('**', ''))
                run.bold = True
            elif line.startswith('- ') or line.startswith('* '):
                doc.add_paragraph(line[2:], style='List Bullet')
            elif line.startswith('1. '):
                doc.add_paragraph(line, style='List Number')
            else:
                doc.add_paragraph(line)

    def add_smart_paragraphs(self, doc, merged_sentences, use_ai_clean=False):
        current_paragraph_text = ""
        target_length = 500
        for item in merged_sentences:
            if use_ai_clean and self.llm_client:
                text = self.clean_text_minimal(item['text'])
            else:
                text = item['text']
            current_paragraph_text += text
            if len(current_paragraph_text) > target_length:
                p = doc.add_paragraph(current_paragraph_text)
                p.paragraph_format.first_line_indent = Inches(0.3)
                p.paragraph_format.line_spacing = 1.5
                current_paragraph_text = ""
        if current_paragraph_text:
            p = doc.add_paragraph(current_paragraph_text)
            p.paragraph_format.first_line_indent = Inches(0.3)
            p.paragraph_format.line_spacing = 1.5

    def create_image_table(self, doc, segments):
        table = doc.add_table(rows=0, cols=2)
        table.style = 'Table Grid'
        cap = cv2.VideoCapture(self.video_path)
        
        for i, seg in enumerate(segments):
            start = seg['start']
            text = seg['text'].strip()
            time_str = self.format_time(start).replace(":", "-")
            ms = int((start % 1) * 100) 
            img_filename = f"frame_{time_str}_{ms:02d}.jpg"
            img_path = os.path.join(self.img_output_dir, img_filename)

            if not os.path.exists(img_path) and cap.isOpened():
                mid_point = start + (seg['end']-start)/2 
                cap.set(cv2.CAP_PROP_POS_MSEC, mid_point * 1000)
                ret, frame = cap.read()
                if ret:
                    try: cv2.imwrite(img_path, frame)
                    except: pass
            
            row_cells = table.add_row().cells
            p = row_cells[0].paragraphs[0]
            run_time = p.add_run(f"[{self.format_time(start)}]\n")
            run_time.bold = True
            run_time.font.color.rgb = RGBColor(0, 51, 102) 
            p.add_run(text)
            
            if os.path.exists(img_path):
                try:
                    p_img = row_cells[1].paragraphs[0]
                    p_img.alignment = WD_ALIGN_PARAGRAPH.CENTER
                    p_img.add_run().add_picture(img_path, width=Inches(3.0))
                except: p_img.add_run("[å›¾ç‰‡]")

        if cap.isOpened(): cap.release()

    @staticmethod
    def format_time(seconds):
        m, s = divmod(seconds, 60)
        h, m = divmod(m, 60)
        return "%02d:%02d:%02d" % (h, m, s)

# --- ä¸»ç¨‹åºå…¥å£ ---
if __name__ == "__main__":
    print("-" * 30)
    print("è§†é¢‘è½¬Word")
    print("-" * 30)
    
    target = input("è¯·è¾“å…¥è§†é¢‘é“¾æ¥ æˆ– æœ¬åœ°æ–‡ä»¶è·¯å¾„:\n>>> ").strip()
    if target:
        base_input = DEFAULT_OUTPUT_BASE
        if not os.path.exists(base_input):
             manual_path = input(f"é»˜è®¤å­˜å‚¨è·¯å¾„: {base_input}\næŒ‰å›è½¦ç¡®è®¤ï¼Œæˆ–è¾“å…¥æ–°è·¯å¾„:\n>>> ").strip()
             if manual_path: base_input = manual_path
        
        if not base_input: base_dir = os.getcwd()
        else: base_dir = base_input.strip('"').strip("'")

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        full_task_dir = os.path.join(base_dir, f"Output_{timestamp}")
        
        if not os.path.exists(full_task_dir):
            try: os.makedirs(full_task_dir)
            except: full_task_dir = os.getcwd()

        print(f"\n[è®¾ç½®] ä»»åŠ¡ç›®å½•: {full_task_dir}")
        converter = VideoToWordConverter(model_size="turbo") 
        converter.run(target, full_task_dir)